{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff4f3454-6723-4af0-b114-31889044ebc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nolr4m\\AppData\\Local\\Temp\\ipykernel_1516\\328282414.py:5: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  movies = pd.read_csv('movies_metadata.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New csv normalized files saved\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import ast\n",
    "\n",
    "movies = pd.read_csv('movies_metadata.csv')\n",
    "ratings = pd.read_csv('ratings.csv')\n",
    "links = pd.read_csv('links.csv')\n",
    "credits = pd.read_csv('credits.csv')\n",
    "keywords = pd.read_csv('keywords.csv')\n",
    "\n",
    "# drop rows where data is missing\n",
    "movies.dropna(inplace=True)\n",
    "ratings.dropna(inplace=True)\n",
    "links.dropna(inplace=True)\n",
    "credits.dropna(inplace=True)\n",
    "keywords.dropna(inplace=True)\n",
    "\n",
    "# normalize numerical values\n",
    "# neural networks perform better for fixed range\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "ratings['rating'] = scaler.fit_transform(ratings[['rating']])\n",
    "\n",
    "#extracting from json the names\n",
    "def extract_names(obj):\n",
    "    try:\n",
    "        obj = ast.literal_eval(obj)\n",
    "        return [d['name'] for d in obj]\n",
    "    except (ValueError, SyntaxError):\n",
    "        return []\n",
    "\n",
    "movies['genres'] = movies['genres'].apply(extract_names)\n",
    "credits['cast'] = credits['cast'].apply(extract_names)\n",
    "keywords['keywords'] = keywords['keywords'].apply(extract_names)\n",
    "\n",
    "# save new csv normalized\n",
    "movies.to_csv('updated/movies_cleaned.csv', index=False)\n",
    "ratings.to_csv('updated/ratings_cleaned.csv', index=False)\n",
    "credits.to_csv('updated/credits_cleaned.csv', index=False)\n",
    "keywords.to_csv('updated/keywords_cleaned.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "print(\"New csv normalized files saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a575e6fe-45bd-463c-90cf-90e7d9689f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load credits.csv\n",
    "credits_df = pd.read_csv('updated/credits_cleaned.csv')\n",
    "movies_metadata_df = pd.read_csv('updated/movies_cleaned.csv')\n",
    "keywords_df = pd.read_csv('updated/keywords_cleaned.csv')\n",
    "ratings_df = pd.read_csv('updated/ratings_cleaned.csv')\n",
    "links_df = pd.read_csv('links.csv')\n",
    "\n",
    "\n",
    "# Merge movies_metadata with credits on 'id'\n",
    "merged_df = pd.merge(movies_metadata_df, credits_df, on='id', how='left')\n",
    "merged_df = pd.merge(merged_df, keywords_df, on='id', how='left')\n",
    "merged_df = pd.merge(merged_df, links_df, left_on='id', right_on='tmdbId', how='left')\n",
    "final_df = pd.merge(merged_df, ratings_df, left_on='id', right_on='movieId', how='left')\n",
    "\n",
    "\n",
    "# Convert JSON-like strings to lists/dictionaries\n",
    "final_df['cast'] = final_df['cast'].apply(ast.literal_eval)\n",
    "final_df['crew'] = final_df['crew'].apply(ast.literal_eval)\n",
    "final_df['keywords'] = final_df['keywords'].apply(ast.literal_eval)\n",
    "\n",
    "print(final_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3679b40-c5d1-4a6b-a636-71c69162500c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nolr4m\\AppData\\Local\\Temp\\ipykernel_4464\\1298021912.py:8: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  movies_metadata = pd.read_csv('movies_metadata.csv', dtype={'id': str})  # Fix DtypeWarning\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on object and int64 columns for key 'id'. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m movies_metadata \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(movies_metadata, credits, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     22\u001b[0m movies_metadata \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(movies_metadata, links, left_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m, right_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmdbId\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m final_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmovies_metadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mratings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmovieId\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Feature engineering\u001b[39;00m\n\u001b[0;32m     26\u001b[0m final_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenres\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m final_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenres\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: [genre[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m genre \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28meval\u001b[39m(x)] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [])\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:170\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _cross_merge(\n\u001b[0;32m    156\u001b[0m         left_df,\n\u001b[0;32m    157\u001b[0m         right_df,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    167\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    168\u001b[0m     )\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 170\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_MergeOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result(copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:807\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_tolerance(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys)\n\u001b[0;32m    805\u001b[0m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[1;32m--> 807\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_coerce_merge_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    809\u001b[0m \u001b[38;5;66;03m# If argument passed to validate,\u001b[39;00m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;66;03m# check if columns specified as unique\u001b[39;00m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;66;03m# are in fact unique.\u001b[39;00m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:1508\u001b[0m, in \u001b[0;36m_MergeOperation._maybe_coerce_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1502\u001b[0m     \u001b[38;5;66;03m# unless we are merging non-string-like with string-like\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m   1504\u001b[0m         inferred_left \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_right \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[0;32m   1505\u001b[0m     ) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   1506\u001b[0m         inferred_right \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_left \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[0;32m   1507\u001b[0m     ):\n\u001b[1;32m-> 1508\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;66;03m# datetimelikes must match exactly\u001b[39;00m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m needs_i8_conversion(lk\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m needs_i8_conversion(rk\u001b[38;5;241m.\u001b[39mdtype):\n",
      "\u001b[1;31mValueError\u001b[0m: You are trying to merge on object and int64 columns for key 'id'. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load data\n",
    "ratings = pd.read_csv('ratings.csv')\n",
    "movies_metadata = pd.read_csv('movies_metadata.csv', dtype={'id': str})  # Fix DtypeWarning\n",
    "keywords = pd.read_csv('keywords.csv')\n",
    "credits = pd.read_csv('credits.csv')\n",
    "links = pd.read_csv('links.csv')\n",
    "\n",
    "# Convert 'id' columns to string (to ensure consistency)\n",
    "movies_metadata['id'] = movies_metadata['id'].astype(str)\n",
    "keywords['id'] = keywords['id'].astype(str)\n",
    "credits['id'] = credits['id'].astype(str)\n",
    "links['tmdbId'] = links['tmdbId'].astype(str)\n",
    "\n",
    "# Merge data\n",
    "movies_metadata = pd.merge(movies_metadata, keywords, on='id', how='left')\n",
    "movies_metadata = pd.merge(movies_metadata, credits, on='id', how='left')\n",
    "movies_metadata = pd.merge(movies_metadata, links, left_on='id', right_on='tmdbId', how='left')\n",
    "final_data = pd.merge(movies_metadata, ratings, left_on='id', right_on='movieId', how='left')\n",
    "\n",
    "# Feature engineering\n",
    "final_data['genres'] = final_data['genres'].apply(lambda x: [genre['name'] for genre in eval(x)] if isinstance(x, str) else [])\n",
    "genres_df = final_data['genres'].apply(lambda x: '|'.join(x) if x else '')\n",
    "genres_df = pd.get_dummies(genres_df.apply(lambda x: x.split('|')).apply(pd.Series).stack())\n",
    "\n",
    "# Group by the index and sum to get one-hot encoded columns\n",
    "genres_df = genres_df.groupby(level=0).sum()\n",
    "\n",
    "# Combine genres with other features\n",
    "X = pd.concat([final_data[['runtime', 'vote_average']], genres_df], axis=1)\n",
    "y = final_data['rating']\n",
    "\n",
    "# Handle missing data\n",
    "X['runtime'].fillna(X['runtime'].mean(), inplace=True)\n",
    "X['vote_average'].fillna(X['vote_average'].mean(), inplace=True)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse ** 0.5\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
